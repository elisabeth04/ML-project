{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Embedding, Dense, TimeDistributed, Concatenate, Attention\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.seq2seq import AttentionWrapper\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../preprocessing/preprocessed.npz')\n",
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "max_text_len = data['max_text_len']\n",
    "max_summary_len = data['max_summary_len']\n",
    "x_voc_size = data['x_voc_size']\n",
    "y_voc_size = data['y_voc_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([378, 189,   8, ...,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an attention mechanism\n",
    "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(keras.layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name = \"att_weight\", shape = (input_shape[-1],1))\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        inputs: x = [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        et = K.squeeze(K.tanh(K.dot(x,self.W)+ self.b), axis = -1)\n",
    "        at = K.expand_dims(K.softmax(et), axis = -1)\n",
    "        output = x*at\n",
    "        return K.sum(output,axis =1)\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build up the Encoder-Decoder architecture using LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1000\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n",
    "def create_model(max_text_len,x_voc_size, hidden_size):\n",
    "    #Encoder\n",
    "    encoder_input = Input(shape=(max_text_len,))\n",
    "    enc_emb = Embedding(x_voc_size, hidden_size,trainable=True)(encoder_input) \n",
    "    \n",
    "    enc_lstm1 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out1, state_h1, state_c1 = enc_lstm1(enc_emb)\n",
    "    \n",
    "    enc_lstm2 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out2, state_h2, state_c2 = enc_lstm2(enc_emb)\n",
    "    \n",
    "    enc_lstm3 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out3, state_h3, state_c3 = enc_lstm3(enc_emb)\n",
    "    \n",
    "    decoder_input = Input(shape = (None,))\n",
    "    dec_emb_layer = Embedding(y_voc_size, hidden_size, trainable = True)\n",
    "    dec_emb = dec_emb_layer(decoder_input) \n",
    "    \n",
    "    dec_lstm = LSTM(hidden_size, return_sequences=True, return_state=True) \n",
    "    dec_outputs,decoder_fwd_state, decoder_back_state = dec_lstm(dec_emb,initial_state=[state_h3, state_c3]) \n",
    "    \n",
    "\n",
    "    print(f\"dec_outputs: {np.shape(dec_outputs)} encoder_out3: {np.shape(encoder_out3)}\")\n",
    "    attention_out = Attention()([encoder_out3,dec_outputs])\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([dec_outputs, attention_out])\n",
    "    decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))  \n",
    "    decoder_outputs = decoder_dense(decoder_concat_input)   \n",
    "    model =Model([encoder_input, decoder_input],decoder_outputs)\n",
    "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy')\n",
    "    return model\n",
    "#attention = AttentionWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_outputs: (None, None, 1000) encoder_out3: (None, 5000, 1000)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 5000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 5000, 1000)   15472000    ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_13 (Embedding)       (None, None, 1000)   15472000    ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_24 (LSTM)                 [(None, 5000, 1000)  8004000     ['embedding_12[0][0]']           \n",
      "                                , (None, 1000),                                                   \n",
      "                                 (None, 1000)]                                                    \n",
      "                                                                                                  \n",
      " lstm_25 (LSTM)                 [(None, None, 1000)  8004000     ['embedding_13[0][0]',           \n",
      "                                , (None, 1000),                   'lstm_24[0][1]',                \n",
      "                                 (None, 1000)]                    'lstm_24[0][2]']                \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 5000, 1000)   0           ['lstm_24[0][0]',                \n",
      "                                                                  'lstm_25[0][0]']                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, 5000, 2000)   0           ['lstm_25[0][0]',                \n",
      "                                                                  'attention_1[0][0]']            \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 5000, 15472)  30959472   ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 77,911,472\n",
      "Trainable params: 77,911,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(max_text_len,x_voc_size, hidden_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
  },
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
