{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Embedding\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.seq2seq import AttentionWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../preprocessing/preprocessed.npz')\n",
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "max_text_len = data['max_text_len']\n",
    "max_summary_len = data['max_summary_len']\n",
    "x_voc_size = data['x_voc_size']\n",
    "y_voc_size = data['y_voc_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build up the Encoder-Decoder architecture using LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1000\n",
    "\n",
    "\n",
    "encoder_input = Input(shape=(max_text_len, ))\n",
    "enc_emb = Embedding(input_dim=x_voc_size, output_dim=hidden_size)(encoder_input)\n",
    "\n",
    "encoder = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder(enc_emb)\n",
    "\n",
    "decoder_input = Input(shape=(None, ))\n",
    "dec_emb = Embedding(input_dim = y_voc_size, output_dim=hidden_size)(decoder_input)\n",
    "\n",
    "decoder = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "decoder_output, state_h, state_c = decoder(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "#attention = AttentionWrapper()\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 5000, 1000)   14535000    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 1000)   14535000    ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 5000, 1000)  8004000     ['embedding_2[0][0]']            \n",
      "                                , (None, 1000),                                                   \n",
      "                                 (None, 1000)]                                                    \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 1000)  8004000     ['embedding_3[0][0]',            \n",
      "                                , (None, 1000),                   'lstm_2[0][1]',                 \n",
      "                                 (None, 1000)]                    'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,078,000\n",
      "Trainable params: 45,078,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3178247cc48992b12ba64927e20c59f571f89d7cdae0a2d20a1a75a447d363b0"
  },
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
